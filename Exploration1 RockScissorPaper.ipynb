{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd545b16",
   "metadata": {},
   "source": [
    "가위바위보 분류기\n",
    "\n",
    "먼저 가위바위보 분류기를 만드는데 필요한 라이브러리를 불러옵니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c2876cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecd1195",
   "metadata": {},
   "source": [
    "\n",
    "224x224의 원본이미지 파일의 크기를 28x28으로 바꾸어주고 저장합니다.\n",
    "\n",
    "이미지가 저장된 디렉토리의 위치를 정확하게 입력해야 이미지를 불러옵니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe3b6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3507  images to be resized.\n",
      "3507  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "3612  images to be resized.\n",
      "3612  images resized.\n",
      "바위 이미지 resize 완료\n",
      "3542  images to be resized.\n",
      "3542  images resized.\n",
      "보 이미지 resize 완료\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1dbf2d",
   "metadata": {},
   "source": [
    "\n",
    "resize를 마친 이미지와 라벨(가위: 0, 바위: 1, 보: 2) 데이터(정답 데이터)를 담을 행렬을 생성합니다.\n",
    "\n",
    "이미지의 개수는 총 10661개이므로 number_of_data=10661으로 입력합니다.\n",
    "\n",
    "resize를 28x28으로 했기 때문에 img_size=28, 이미지가 흑백이 아닌 컬러이기에 color=3입니다.\n",
    "\n",
    "또한, 이미지 resize를 할 때처럼 이미지의 디렉토리 위치를 확인해줍니다.\n",
    "\n",
    "이후 .shape를 통해서 train data가 잘 담겼는지 확인합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04311cf8",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c82abcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 10661 입니다.\n",
      "x_train shape: (10661, 28, 28, 3)\n",
      "y_train shape: (10661,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=10661):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf3200",
   "metadata": {},
   "source": [
    "\n",
    "train data를 불러와서 한 번 확인해봅니다.\n",
    "\n",
    "저는 무작위로 x_train에 7을 넣어서 확인했습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d4fcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[7])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf4070",
   "metadata": {},
   "source": [
    "\n",
    "train data가 잘 담긴 것을 확인했으니, 딥러닝 네트워크를 설계합니다.\n",
    "\n",
    "keras 라이브러리를 통해서 만들어줍니다.\n",
    "\n",
    "28x28 사이즈의 컬러 이미지이기 때문에 input_shape=(28,28,3)으로 입력합니다.\n",
    "\n",
    "가위바위보 이미지 분류의 결과는 가위, 바위, 보 3가지이기 때문에 최종 분류기의 클래스 수를 3으로 입력합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85aad951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                25616     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 45,059\n",
      "Trainable params: 45,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe16ea",
   "metadata": {},
   "source": [
    "\n",
    "딥러닝 네트워크를 설계한 다음에는 딥러닝 네트워크를 학습시킵니다.\n",
    "\n",
    "epoch는 10661개의 데이터를 학습시키는 반복 학습시키는 수를 말합니다.\n",
    "\n",
    "인식 정확도를 높이기 위해서 저는 20번 반복 학습시켰습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7a8778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 4s 3ms/step - loss: 2.7846 - accuracy: 0.4819\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.6917 - accuracy: 0.6623\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.5260 - accuracy: 0.7398\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.7800\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.3811 - accuracy: 0.8207\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.3128 - accuracy: 0.8555\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.2535 - accuracy: 0.8847\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.2138 - accuracy: 0.9130\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1670 - accuracy: 0.9330\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1401 - accuracy: 0.9431\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1275 - accuracy: 0.9496\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1011 - accuracy: 0.9603\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1117 - accuracy: 0.9576\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1083 - accuracy: 0.9596\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1109 - accuracy: 0.9589\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9715\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.1364 - accuracy: 0.9480\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.0655 - accuracy: 0.9744\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9761\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.0457 - accuracy: 0.9826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89881f81f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cab3c3",
   "metadata": {},
   "source": [
    "\n",
    "이제 test data를 통해서 위의 가위바위보 분류기가 잘 만들어졌는지, 분류의 정확도는 얼마나 되는지를 확인해봅니다.\n",
    "\n",
    "train data를 불러올 때와 같이 test data의 이미지를 28x28으로 resize한 이후 저장합니다.\n",
    "\n",
    "또한 이미지가 저장된 디렉토리의 위치를 정확하게 입력해야 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27bab0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900  images to be resized.\n",
      "900  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "900  images to be resized.\n",
      "900  images resized.\n",
      "바위 이미지 resize 완료\n",
      "900  images to be resized.\n",
      "900  images resized.\n",
      "보 이미지 resize 완료\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e605e78",
   "metadata": {},
   "source": [
    "\n",
    "가위 900개, 바위 900개, 보 900개의 이미지를 resize 했습니다.\n",
    "\n",
    "train data를 담는 행렬을 만들때 처럼, 총 2700개의 이미지이기에 number_of_data=2700으로 입력합니다.\n",
    "\n",
    "이미지의 사이즈가 28x28이고 컬러 이미지이기에 img_size=28, color=3 입니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f76ff846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 2700 입니다.\n",
      "x_test shape: (2700, 28, 28, 3)\n",
      "y_test shape: (2700,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=2700):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dffc8f6",
   "metadata": {},
   "source": [
    "\n",
    "이제 test data가 담긴 것을 확인했습니다.\n",
    "\n",
    "가위바위보 분류기가 잘 작동하는 지를 확인하기 위해서 test data의 정확도를 확인해봅니다.\n",
    "\n",
    "정확도는 아래 보는 것처럼 0.6448 가 나왔습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e19e89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 - 0s - loss: 3.8374 - accuracy: 0.6448\n",
      "test_loss: 3.8373818397521973 \n",
      "test_accuracy: 0.6448147892951965\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe13f58",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "회고\n",
    "\n",
    "\n",
    "처음으로 진행하는 Exploration의 프로젝트는 생각보다 쉽지 않았다.\n",
    "\n",
    "대부분의 코드가 앞선 예제에서 주어져 있었고 조금만 수정하면 되어 다행이었지만, 데이터셋을 구하고 하는 점이 까다로웠다.\n",
    "\n",
    "\n",
    "1차 시도\n",
    "\n",
    "\n",
    "처음에 train data를 내 손으로 찍은 가위 100장, 바위 100장 보 100장 총 300장 훈련시켰다.\n",
    "\n",
    "데이터의 수가 적으니 epoch가 3~4가 넘어가니 정확도가 1이 넘어갔고 오버피팅이 일어났다.\n",
    "\n",
    "test data는 아이펠에서 제공한 300개의 데이터를 사용했다.\n",
    "\n",
    "train data의 개수가 적고 오버피팅이 일어나서 그런지 test의 정확도는 0.3333이 계속 나왔다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2차 시도\n",
    "\n",
    "\n",
    "train data의 개수가 적으면 test의 정확도가 낮게 나온다고 생각해서 train data를 가위, 바위, 보 각 5000개, 총 15000개로 늘렸다.\n",
    "\n",
    "여기서 train data는 전부 다 내 손 사진이었다.\n",
    "\n",
    "train data의 수가 50배 정도 늘었지만, test data의 정확도는 0.4xx 정도로 그다지 높아지지 않았다.\n",
    "\n",
    "그 이유는 train data가 모두 내 손으로 찍어서 다양성이 부족했고, 15000개의 train data의 개수에 비해서 test data는 100개로 적었다.\n",
    "\n",
    "대부분 train data와 test data의 비율은 8:2, 7:3 정도인데 나의 경우 9.9:0.1 정도였다.\n",
    "\n",
    "train data와 test data의 다양성이 부족하고 비율도 맞지 않은 점이 문제이기에 수정해야만 했다.\n",
    "\n",
    "\n",
    "\n",
    "3차 시도\n",
    "\n",
    "\n",
    "train data를 15000장의 내 사진이 아니라 내 손 사진에 다른 사람들의 사진을 더해서 다양하게 만들어줬다.\n",
    "\n",
    "이렇게 train data를 다양화시키니 오버피팅이 발생하지 않았다.\n",
    "\n",
    "test data도 아이펠에서 제공한 사진에 더해서 2700개로 다양화시켰다.\n",
    "\n",
    "이렇게 바꾸니 train data와 test data의 비율이 7.5:2.5 정도였고 적절한 비율이었다.\n",
    "\n",
    "test data의 정확도가 0.5xx 정도가 나왔다.\n",
    "\n",
    "조금 더 정확도를 높이기 위해서 딥러닝 네트워크 설계의 Conv2D의 수를 높이고 epoch의 횟수를 높여줬다.\n",
    "\n",
    "그러니 test data가 0.6448로 3분의 2 정도는 식별할 수 있는 수준이 되었다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "저는 이렇게 3번 정도 데이터셋을 수정하며 가위바위보 분류기의 정확도를 높였습니다.\n",
    "\n",
    "당연한 이야기이겠으나 이번 프로젝트를 통해서 train data와 test data의 다양성 및 개수의 중요함도 알게 되었고, \n",
    "\n",
    "데이터를 구하는 것 자체도 어렵다는 점을 몸소 체험하게 되었습니다.\n",
    "\n",
    "다행인 점은 데이터를 수정하며 정확도가 높아지니 뿌듯하고 기분도 좋았다는 것입니다.\n",
    "\n",
    "그래도 쉽지 않네요....\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
