{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03133c0",
   "metadata": {},
   "source": [
    "# 뉴스기사 요약해보기\n",
    "\n",
    "### 필요한 라이브러리 불러오기\n",
    "### NLTK 패키지에서 불용어 사전을 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c479798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f18b0",
   "metadata": {},
   "source": [
    "### 전체 샘플수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ed17ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98401\n"
     ]
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb5d83",
   "metadata": {},
   "source": [
    "#### 샘플 중 10개를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df96af0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83514</th>\n",
       "      <td>Kumble has been absolutely impeccable: BCCI pa...</td>\n",
       "      <td>Vinod Rai, head of BCCI's Committee of Adminis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44813</th>\n",
       "      <td>Not clear on what authority ED searched Nirav'...</td>\n",
       "      <td>The Delhi High Court on Wednesday said it's no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61682</th>\n",
       "      <td>JEE Main, NEET likely to be conducted twice a ...</td>\n",
       "      <td>After the Centre cleared the proposal for form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69893</th>\n",
       "      <td>Maha govt proposes water cess hike, beer to be...</td>\n",
       "      <td>The Maharashtra government has proposed an inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37809</th>\n",
       "      <td>Hope I look like my hero when I'm 60 plus: Tig...</td>\n",
       "      <td>Actor Tiger Shroff shared his father and actor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27011</th>\n",
       "      <td>Burari family began getting havan material wee...</td>\n",
       "      <td>Members of the family which was found dead in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87436</th>\n",
       "      <td>No more hookahs in smoking zones of restaurant...</td>\n",
       "      <td>The Centre has amended rules linked to smoking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22939</th>\n",
       "      <td>There are no jobs: Nitin Gadkari on demand for...</td>\n",
       "      <td>Replying to a query on Maratha community's agi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28942</th>\n",
       "      <td>Massive fire in Delhi still on after 17 hrs, A...</td>\n",
       "      <td>Indian Air Force has joined the operation to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94129</th>\n",
       "      <td>Won't be able to write about my life in a book...</td>\n",
       "      <td>Actor Salman Khan has said that he would never...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "83514  Kumble has been absolutely impeccable: BCCI pa...   \n",
       "44813  Not clear on what authority ED searched Nirav'...   \n",
       "61682  JEE Main, NEET likely to be conducted twice a ...   \n",
       "69893  Maha govt proposes water cess hike, beer to be...   \n",
       "37809  Hope I look like my hero when I'm 60 plus: Tig...   \n",
       "27011  Burari family began getting havan material wee...   \n",
       "87436  No more hookahs in smoking zones of restaurant...   \n",
       "22939  There are no jobs: Nitin Gadkari on demand for...   \n",
       "28942  Massive fire in Delhi still on after 17 hrs, A...   \n",
       "94129  Won't be able to write about my life in a book...   \n",
       "\n",
       "                                                    text  \n",
       "83514  Vinod Rai, head of BCCI's Committee of Adminis...  \n",
       "44813  The Delhi High Court on Wednesday said it's no...  \n",
       "61682  After the Centre cleared the proposal for form...  \n",
       "69893  The Maharashtra government has proposed an inc...  \n",
       "37809  Actor Tiger Shroff shared his father and actor...  \n",
       "27011  Members of the family which was found dead in ...  \n",
       "87436  The Centre has amended rules linked to smoking...  \n",
       "22939  Replying to a query on Maratha community's agi...  \n",
       "28942  Indian Air Force has joined the operation to d...  \n",
       "94129  Actor Salman Khan has said that he would never...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d9923d",
   "metadata": {},
   "source": [
    "### text만 훈련에 사용하기에 text만 저장하고 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdb6e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39749</th>\n",
       "      <td>Congress MP Shashi Tharoor has been summoned b...</td>\n",
       "      <td>Shashi Tharoor to stand trial in wife Sunanda'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14505</th>\n",
       "      <td>Actress-turned-producer Pooja Bhatt, while spe...</td>\n",
       "      <td>Women who speak uncomfortable truths are calle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>Indian commentator Harsha Bhogle chose Virat K...</td>\n",
       "      <td>Harsha Bhogle names Kohli in his 2018 dream OD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62033</th>\n",
       "      <td>India has slipped to 7th position in the busin...</td>\n",
       "      <td>India at 7th position in business optimism ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64936</th>\n",
       "      <td>The Indian Railways will soon cut short the ru...</td>\n",
       "      <td>500 long-distance trains to run faster from ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25080</th>\n",
       "      <td>Fifty years after an AN-12 aircraft of the Ind...</td>\n",
       "      <td>Body of soldier found after 50 years in Himach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20883</th>\n",
       "      <td>Swimmer Sajan Prakash, who set a national reco...</td>\n",
       "      <td>Swimmer posts record Asiad finish as family mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15056</th>\n",
       "      <td>Historian Irfan Habib on Monday accused the BJ...</td>\n",
       "      <td>BJP treats Gandhi as senior sanitary inspector...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68242</th>\n",
       "      <td>Vice-chancellor of Banaras Hindu University Gi...</td>\n",
       "      <td>Girls who don't go out don't complain: BHU VC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95736</th>\n",
       "      <td>Seeking Foreign Minister Sushma Swaraj's help ...</td>\n",
       "      <td>Should I kill myself over visa issue, tweets u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80716</th>\n",
       "      <td>United States President Donald Trump complimen...</td>\n",
       "      <td>You're in good shape: Trump to French Prez's 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7685</th>\n",
       "      <td>As many as 3,026 buildings in Mumbai have been...</td>\n",
       "      <td>3026 Mumbai buildings defy fire safety norms; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47434</th>\n",
       "      <td>An Indian-origin man has been sentenced to ove...</td>\n",
       "      <td>Indian-origin man jailed for filming girls in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>Former Jammu and Kashmir CM Farooq Abdullah on...</td>\n",
       "      <td>Be tolerant like Vajpayee: Ex-J&amp;K CM Farooq Ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42729</th>\n",
       "      <td>Urmila Matondkar will be making her comeback i...</td>\n",
       "      <td>Urmila to make Bollywood comeback with a song ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "39749  Congress MP Shashi Tharoor has been summoned b...   \n",
       "14505  Actress-turned-producer Pooja Bhatt, while spe...   \n",
       "4405   Indian commentator Harsha Bhogle chose Virat K...   \n",
       "62033  India has slipped to 7th position in the busin...   \n",
       "64936  The Indian Railways will soon cut short the ru...   \n",
       "25080  Fifty years after an AN-12 aircraft of the Ind...   \n",
       "20883  Swimmer Sajan Prakash, who set a national reco...   \n",
       "15056  Historian Irfan Habib on Monday accused the BJ...   \n",
       "68242  Vice-chancellor of Banaras Hindu University Gi...   \n",
       "95736  Seeking Foreign Minister Sushma Swaraj's help ...   \n",
       "80716  United States President Donald Trump complimen...   \n",
       "7685   As many as 3,026 buildings in Mumbai have been...   \n",
       "47434  An Indian-origin man has been sentenced to ove...   \n",
       "7207   Former Jammu and Kashmir CM Farooq Abdullah on...   \n",
       "42729  Urmila Matondkar will be making her comeback i...   \n",
       "\n",
       "                                               headlines  \n",
       "39749  Shashi Tharoor to stand trial in wife Sunanda'...  \n",
       "14505  Women who speak uncomfortable truths are calle...  \n",
       "4405   Harsha Bhogle names Kohli in his 2018 dream OD...  \n",
       "62033  India at 7th position in business optimism ran...  \n",
       "64936  500 long-distance trains to run faster from ne...  \n",
       "25080  Body of soldier found after 50 years in Himach...  \n",
       "20883  Swimmer posts record Asiad finish as family mi...  \n",
       "15056  BJP treats Gandhi as senior sanitary inspector...  \n",
       "68242      Girls who don't go out don't complain: BHU VC  \n",
       "95736  Should I kill myself over visa issue, tweets u...  \n",
       "80716  You're in good shape: Trump to French Prez's 6...  \n",
       "7685   3026 Mumbai buildings defy fire safety norms; ...  \n",
       "47434  Indian-origin man jailed for filming girls in ...  \n",
       "7207   Be tolerant like Vajpayee: Ex-J&K CM Farooq Ab...  \n",
       "42729  Urmila to make Bollywood comeback with a song ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['text','headlines']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 15개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f355838",
   "metadata": {},
   "source": [
    "#### 중복되지 않는 샘플의 수를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f416cb97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d90f65",
   "metadata": {},
   "source": [
    "#### 중복이 존재함을 알 수 있기에 중복되는 샘플을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f622bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560e017",
   "metadata": {},
   "source": [
    "#### 데이터 프레임에 null 값이 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fad780d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text         0\n",
      "headlines    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebbfa54",
   "metadata": {},
   "source": [
    "### 텍스트 정규화 사전 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221ae215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a4b9b2",
   "metadata": {},
   "source": [
    "### 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4edb96ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa99120a",
   "metadata": {},
   "source": [
    "### 데이터 전처리 함수 만들기\n",
    "#### 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2505dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee19d375",
   "metadata": {},
   "source": [
    "#### 임의의 text를 만들어 놓은 전처리 함수로 전처리 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51e7c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'tokens' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_126/2306156410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"headlines:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_headlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 불용어를 제거하지 않습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_126/1291583206.py\u001b[0m in \u001b[0;36mpreprocess_sentence\u001b[0;34m(sentence, remove_stopwords)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'tokens' referenced before assignment"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_headlines = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"headlines:\", preprocess_sentence(temp_headlines, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc645a",
   "metadata": {},
   "source": [
    "### text를 전처리 후, 상위 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5030ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_text = []\n",
    "# 전체 text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855e48f",
   "metadata": {},
   "source": [
    "### headlines를 전처리 후, 상위 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_headlines = []\n",
    "# 전체 headlines 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(\"headlines 전처리 후 결과: \", clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8071fd3d",
   "metadata": {},
   "source": [
    "#### 빈 값을 가진 샘플이 있으면, Null 값으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf79d6",
   "metadata": {},
   "source": [
    "#### null 값이 생겼는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9773a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0257d",
   "metadata": {},
   "source": [
    "### text의 최소 길이, 최대 길이, 평균 길이를 구하고 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e6f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca697206",
   "metadata": {},
   "source": [
    "### text의 최대 길이를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6551df",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "headlines_max_len = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ecc69a",
   "metadata": {},
   "source": [
    "### 훈련 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 해당하는지 계산하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dcc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28430a70",
   "metadata": {},
   "source": [
    "#### 함수에 텍스트를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3485f85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177404b2",
   "metadata": {},
   "source": [
    "### 정해진 길이보다 길면 제외하는 방법으로 데이터를 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206518b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424019b4",
   "metadata": {},
   "source": [
    "### 시작 토큰과 종료 토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae92fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a75c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
